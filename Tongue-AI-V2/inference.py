import os
import torch
import cv2
import numpy as np
import pandas as pd
from PIL import Image
from model import SignOrientedNetwork
import albumentations as A
from albumentations.pytorch import ToTensorV2

# 1. è¨­å®š
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
MODEL_PATH = 'signnet_best_fold1.pth'  # ä½ çš„æ¬Šé‡æª”å
UKAN_DIR = 'mimi/ukan'                 # UKAN åœ–ç‰‡è·¯å¾‘
LABEL_COLS = ['TonguePale', 'TipSideRed', 'Spot', 'Ecchymosis',
              'Crack', 'Toothmark', 'FurThick', 'FurYellow']

# 2. é è™•ç†å‡½æ•¸ (å¿…é ˆèˆ‡è¨“ç·´æ™‚ä¸€è‡´)
def get_three_views(img_np):
    resized = cv2.resize(img_np, (224, 224), interpolation=cv2.INTER_LINEAR)
    gray = cv2.cvtColor(resized, cv2.COLOR_RGB2GRAY)
    _, mask = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)
    kernel_size = int(np.sqrt(224**2 + 224**2) * 0.191)
    kernel = np.ones((kernel_size, kernel_size), np.uint8)
    mask_eroded = cv2.erode(mask, kernel, iterations=1)
    mask_edge = cv2.subtract(mask, mask_eroded)
    mask_edge[:224 // 4, :] = 0
    mask_body = cv2.subtract(mask, mask_edge)
    body_img = cv2.bitwise_and(resized, resized, mask=mask_body)
    edge_img = cv2.bitwise_and(resized, resized, mask=mask_edge)
    return resized, body_img, edge_img

transform = A.Compose([
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2()
])

# 3. è¼‰å…¥æ¨¡å‹
print(f"ğŸ”„ æ­£åœ¨è¼‰å…¥æ¨¡å‹: {MODEL_PATH}")
checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)
model = SignOrientedNetwork(num_classes=len(LABEL_COLS), backbone='swin_base_patch4_window7_224')
model.load_state_dict(checkpoint['model_state_dict'])
model.to(DEVICE)
model.eval()

# ç²å–è¨“ç·´æ™‚çš„æœ€ä½³é–¾å€¼ (å¦‚æœæ²’æœ‰å°±ç”¨ 0.5)
best_thresholds = checkpoint.get('best_thresholds', [0.5] * len(LABEL_COLS))

# 4. é–‹å§‹é æ¸¬
results = []
img_files = [f for f in os.listdir(UKAN_DIR) if f.endswith(('.png', '.jpg', '.jpeg'))]

print(f"ğŸš€ é–‹å§‹é æ¸¬ {len(img_files)} å¼µåœ–ç‰‡...")

with torch.no_grad():
    for f in img_files:
        path = os.path.join(UKAN_DIR, f)
        img_np = np.array(Image.open(path).convert('RGB'))
        
        # è™•ç†æˆä¸‰åˆ†æ”¯è¼¸å…¥
        w, b, e = get_three_views(img_np)
        w_t = transform(image=w)['image'].unsqueeze(0).to(DEVICE)
        b_t = transform(image=b)['image'].unsqueeze(0).to(DEVICE)
        e_t = transform(image=e)['image'].unsqueeze(0).to(DEVICE)
        
        # æ¨è«–
        logits = model(w_t, b_t, e_t)['final']
        probs = torch.sigmoid(logits).cpu().numpy()[0]
        
        # æ ¹æ“šé–¾å€¼åˆ¤å®šçµæœ
        pred_tags = {}
        for i, col in enumerate(LABEL_COLS):
            pred_tags[col] = 1 if probs[i] >= best_thresholds[i] else 0
            # åŒæ™‚å­˜å…¥æ©Ÿç‡å€¼æ–¹ä¾¿å¾ŒçºŒåˆ†æ
            pred_tags[f"{col}_prob"] = round(float(probs[i]), 4)
            
        pred_tags['filename'] = f
        results.append(pred_tags)

# 5. è¼¸å‡ºçµæœ
df_res = pd.DataFrame(results)
df_res.to_csv('mimi_prediction_results.csv', index=False)
print("âœ… é æ¸¬å®Œæˆï¼çµæœå·²å„²å­˜è‡³ mimi_prediction_results.csv")
print(df_res[['filename'] + LABEL_COLS].head()) # é¡¯ç¤ºå‰å¹¾ç­†çœ‹çœ‹